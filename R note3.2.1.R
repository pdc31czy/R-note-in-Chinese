#3.2.1 单个总体均值的t检验


# （1）什么是检验？
# 检验（test）是统计学中最重要的概念之一，在科学研究和实际业务中都有着广泛的应用。用一句话来概括就是：人们希望通过掌握的数据和其他背景知识确认某个假设是否成立（比如某种药物是否有效，股票是否有上扬的趋势，一种汽车的油耗是否为15mpg，一组病人血压的均值是否大于120mmHg）。下面我们来举个栗子。
# 
# 考虑一个只有赢或者输两种情况的赌局，每次获胜的概率是未知的，这里设为p。一个赌徒想要确认在这个赌局中每次获胜的概率是否是0.5，或者说他希望确认这是一个公平的赌局。如果每次获胜的概率不是（更严格地说是小于等于）0.5，那么这名赌徒就不希望进入这个对他不利的赌局。在这里，这个未知的参数p是关键。假如这名赌徒旁观了其他人参加这个赌局获胜的情况，其他人一共赌了100局，其中获胜30次，我们如何通过这组数据（样本）来判断获胜概率是否是0.5呢？
# 
# 在这个例子中，我们掌握了赌100次的获胜情况（数据），并且知道这个赌局只有输赢两种情况，每次获胜的概率p都是一样的（背景知识），我们希望确认p =
#   0.5这个假设是否成立。统计学中解决此类问题的思路是：假设未知参数（p）是特定的值，然后通过数据判断这个假设是否合理（建立检验统计量等），如果不合理，我们可以拒绝这个假设；如果合理，那么我们持保留意见，不去拒绝假设。
# 
# 这里，我们假设p = 0.5，统计学中也常常写作，H0：p = 0.5，也就是原假设：p = 0.5。
# 
# 如果这个赌局是公平的，那么一个人赌100局却只赢30局甚至更少的概率是多少呢？通过计算可以得知这个概率大概是4×10???5，也就是说，在一个公平的赌局下，一个人输那么惨，或者比这还惨的可能性是4×10???5（小概率事件），这看起来不太可能，得是做了多少坏事人品才能这么差。更可能是因为这个赌局本身就是不公平的（p不是0.5）才导致这个人输得那么惨。在这种情况下，我们认为之前的假设是不对的，统计学中也称作拒绝原假设。因此，认为这个赌局并不是公平的，也就是说我们拒绝了p =
#   0.5这个假设。




# （2）学生t检验
# 对于不同的假设和问题，统计学上有不同的检验来处理，以上的例子只是检验的一个特例而已。今天我们要说的是非常常用的单个总体均值的假设检验，也称为学生t检验。学生t检验简称t检验，最早由William Sealy Gosset于1908年提出。Gosset受雇于都柏林的健力士酿酒厂担任统计学家,  他提出了t检验以降低啤酒质量监控的成本，并于1908年在《Biometrika》期刊上公布t检验，但因为商业机密的原因而被迫使用笔名Student，因此这个检验就叫做学生t检验。那么t检验通常用来解决哪类问题呢？
# 
# 如果我们有一组从正态总体（背景知识）中抽出的样本（数据），但总体的平均水平未知，我们希望通过这组样本确认总体的平均水平是多少，t检验就大有作为了。在这里我们通过著名的Iris数据来说明一下t检验的思想和在R语言中的实现。
# 
# Iris数据测量了三种鸢（yuan，一声）尾花卉的一些值，我们只看山鸢尾（setosa）这种植物的花萼长度的测量。首先我们在R中取出这个数据集：

rm(list = ls())  # 清空工作空间
summary(iris)
##    Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
##   Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
##   1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
##   Median :5.800   Median :3.000   Median :4.350   Median :1.300  
##   Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
##   3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
##   Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
##         Species  
##   setosa    :50  
##   versicolor:50  
##   virginica :50  
##                  
##                  
##  
(sepal = iris[iris$Species == 'setosa', 1])
##   [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4
##  [18] 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5
##  [35] 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0

#Iris数据集对50个setosa的花萼进行了测量，假设每个花萼的长度都是来自一个正态分布，但这个正态分布的总体均值μ（位置参数），和总体方差σ2（尺度参数）都是不知道的。如果这时候有个植物学家跑过来跟你说，他对基因组的分析表明，这种植物花萼的总体均值是4.5cm，而我们想通过数据来看一看他的分析是否值得信赖。在这里，假设H0:μ=4.5cm。R可以给我们计算最后的结果，也就是我们是否应该同意μ是4.5cm。

t.test(sepal, mu = 4.5)
##  
##      One Sample t-test
##  
##  data:  sepal
##  t = 10.151, df = 49, p-value = 1.223e-13
##  alternative hypothesis: true mean is not equal to 4.5
##  95 percent confidence interval:
##   4.905824 5.106176
##  sample estimates:
##  mean of x 
##      5.006

# 看起来结果有一些杂乱，我们教给大家查看结果最快的两种方式，这两种方式是等价的，读者可选用任何一种方式，但这两种方法却忽略了一些其他信息，稍后向大家说明。
# 
# 红字p-value：如果小于0.05那么我们就拒绝原假设，也就是说我们认为花萼的均值不是4.5cm。如果p-value大于0.05，那么我们就不能拒绝原假设，也就是说我们认为这名植物学家说的话很可能是正确的，花萼的均值很有可能是4.5cm，我们并不能拒绝这一说法。
# 
# 如果4.5不在绿字95 percent confidence interval的区间里面，也就是说如果4.5不在4.905824，5.106176之间的话，（在0.05的显著性水平下）拒绝原假设，否则的话不能拒绝原假设。



# （3）t检验进阶
# 上面就是t检验的思想和应用，下面我们稍微看一些t检验的变种形式和一些其他的信息。
# 
# 进行t检验的一个重要前提是我们的数据是来自一个正态分布，其中方差未知。如果我们知道方差的话，那么我们应该利用这一信息从而获得更佳的结果，这时候我们应该使用z检验（检验统计量服从正态分布）。
# 
# 那么如何确认数据是否来自正态分布呢？一般来说有两种方法，第一种是问专家，查看历史情况。当然这是比较理想的情况，如果我们对这一数据没有太多的背景知识，我们可以利用Q-Q图或者一些正态性检验（非参数检验方法）来判断数据是否来自正态分布。
# 
# 如果数据不是来自于正态分布那怎么办呢？在样本量很大的情况下，我们还是可以继续使用t检验的，虽然它不是特别精确了。当然如果读者还是想保守一点的话可以使用非参数的方法，这里就不再赘述了。2和3只是给大家提供一点变招，如果大家在实际数据分析中遇到类似的问题也有章可循。
# 
# 如果这名植物学家说花萼的长度应该是一个大于4.5cm的数，但是具体是多少不太清楚。在这种情况下我们只需要调整一个参数就可以（单边假设检验）。

t.test(sepal, mu = 4.5, alternative = "less")
##  
##      One Sample t-test
##  
##  data:  sepal
##  t = 10.151, df = 49, p-value = 1
##  alternative hypothesis: true mean is less than 4.5
##  95 percent confidence interval:
##       -Inf 5.089575
##  sample estimates:
##  mean of x 
##      5.006


# 这里alternative参数是指备择假设（的方向）。
# 
# p-value反映了我们有多大的信心去拒绝原假设。列举前面硬币的例子，如果我们观察到100局中只获胜了10局，那么我们的数据更加倾向于去拒绝原假设，也就是说我们更有信心去拒绝原假设。这种情况下p-value都是很小的。换句话说，p-value越小，我们越有信心去拒绝原假设。
# 
# 也许有些读者已经注意到t.test()输出结果中的confidence interval了，对了，这就是置信区间。假设检验和置信区间存在一一对应的关系，调用函数t.test()的时候R会一并给出位置参数μ的置信区间。对于检验来说，只要我们假设的数字（这里是4.5）不在置信区间内，我们就拒绝原假设，否则我们就不能拒绝原假设。
# 
# 有些读者可能会问为什么一定要p-value小于0.05才能拒绝原假设呢？这里就会牵扯出显著性水平这个比较抽象的概念。在此我们不对显著性追根溯源（醒醒，这是R语千寻，不是数理统计课），只是提醒读者，一般显著性水平会选择0.1，0.05，和0.01这三个水平。




# （4）总结
# 当我们有一组来自未知均值、未知方差的正态分布的样本，想判断它的总体均值是否等于（有时是大于或者小于）某个给定值的情况下，单样本t检验就可以派上用场了。我们可以在R中调用t.test()函数来进行单样本的t检验，t.test()的部分参数列表如下：

help("t.test")


# x：待检验的数据集，要求是numeric vector
# 
# alternative：备择假设的方向，分别对应双边、左侧和右侧检验
# 
# mu：原假设中想要检验的总体均值
# 
# conf.level：置信水平，对应着输出的置信区间



# 注：
# 
# 1. 做单边假设检验的时候总是令人头晕，搞不清哪边做原假设哪边做备择假设。一般情况下，我们能够控制犯第一类错误的概率（拒真），也就是我们更希望得到拒绝原假设的结论，因此常常把样本支持的证据放在备择假设。
# 2. 本文基本上列举了t检验在实际数据分析中的一些要点（契合R语言操作），想要了解更多理论基础的读者，可以参考数理统计教材里面的假设检验章节。







##########################################################
#总结#


t.test(x,alternative = c("two.sided","less","greater"),mu=0,conf.level = 0.95,...)
# x：待检验的数据集，要求是numeric vector
# alternative：备择假设的方向，分别对应双边、左侧和右侧检验
# mu：原假设中想要检验的总体均值
# conf.level：置信水平，对应着输出的置信区间


#p-value反映了我们有多大的信心去拒绝原假设
#p-value越小，我们越有信心去拒绝原假设
#一般显著性水平会选择0.1，0.05，和0.01这三个水平


#t.test()输出结果中的置信区间（confidence interval）
#假设检验和置信区间存在一一对应的关系，调用函数t.test()的时候R会一并给出位置参数μ的置信区间
#只要我们假设的数字不在置信区间内，我们就拒绝原假设，否则我们就不能拒绝原假设


##########################################################










